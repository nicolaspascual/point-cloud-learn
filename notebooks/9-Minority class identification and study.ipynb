{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.local/share/virtualenvs/point-cloud-learn-97nGMN1k/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/home/nicolas/.local/share/virtualenvs/point-cloud-learn-97nGMN1k/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('../')\n",
    "\n",
    "import time\n",
    "\n",
    "from src.data_loader import load_data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from multiprocessing.pool import Pool\n",
    "from functools import partial\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minority class identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, _ = load_data('../data/huge_sample_input_classified.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete columns with one value\n",
    "for col in clusters.columns:\n",
    "    if len(clusters[col].unique()) == 1:\n",
    "        clusters.drop(col,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarize\n",
    "clusters['classification'] = (\n",
    "    ((clusters['classification'] != 'Vegetation') & (clusters['classification'] != 'Limit_effect'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac24773511634cfc9668615a6bbcd7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=26, description='k', max=50, min=2), Output()), _dom_classes=('widget-inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_label(p):\n",
    "    if p < 1/5:\n",
    "        return 'Outlier'\n",
    "    elif p < 2/5:\n",
    "        return 'Rare'\n",
    "    elif p < 4/5:\n",
    "        return 'Border Line'\n",
    "    return 'Safe'\n",
    "\n",
    "def calculate_ordered_distances(i, df):\n",
    "    element = df.loc[i]\n",
    "    distances_class = []\n",
    "\n",
    "    for _, target_element in df.loc[~clusters.index.isin([i])].iterrows():\n",
    "        distance = np.linalg.norm(target_element.drop('classification') - element.drop('classification'))\n",
    "        distances_class.append((distance, target_element['classification']))\n",
    "\n",
    "    return sorted(distances_class, key=lambda p: p[0])\n",
    "\n",
    "\n",
    "@interact\n",
    "def show_types_of_minorities(k=(2, 50, 1)):\n",
    "    global distances\n",
    "    if not ('distances' in vars() or 'distances' in globals()):\n",
    "        with Pool(3) as pool:\n",
    "            distances = pool.map(\n",
    "                partial(calculate_ordered_distances, df=clusters),\n",
    "                clusters[clusters['classification'] == True].index\n",
    "            )\n",
    "        \n",
    "    classes = [[e[1] for e in  d[:k]] for d in distances]\n",
    "    element_types = [get_label(sum(l) / len(l)) for l in classes]\n",
    "    element_types, counts = np.unique(element_types, return_counts=True)\n",
    "    plt.pie(counts, labels=element_types, autopct='%1.1f%%')\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset is composed by almost all rare and outlier examples we must apply methods in the following table:\n",
    "\n",
    "| PreProcess | Average Rank |\n",
    "|------------|--------------|\n",
    "| SMOTE      | 3.9          |\n",
    "| SPIDER     | 3.8          |\n",
    "| NCR        | 3.4          |\n",
    "\n",
    "Extracted from _\"Napierala 2015\"_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
